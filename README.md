# PCA Demo

This is a custom implementation of the PCA dimensionality reduction algorithm! I would not recommend using it for your data projects, but you can use it to play around with and visualize PCA in 2D and 3D cases!

## General Algorithm

Since PCA compares the relative importance of different features, it is very important they each one is the same scale. The first step is to standardize each feature by its mean and standard deviation.

The next step is to compute a covariance matrix between the standardized features.

Afterwards, compute the eigenvalues and eigenvectors of the covariance matrix. If needed, sort them in descending order by eigenvalue. Covariance matrices are symmetric, so the eigenvalues should be nonnegative.

Take the $k$ eigenvectors corresponding to the $k$ largest eigenvalues to be the projection matrix. This matrix can be applied to your standardized data to reduce its dimensionality while maintaining the majority of the information!

These steps are implemented in `pca_serial.c` with the help of some functions written in `utils/serial.c`. These are by no means the most efficient or popular methods used from linear algebra, but they seemed simple enough to write up quickly.

Some sample data and graphs are generated by the Python files in the `data` folder. More on that below.

## Usage

Run the demo script with the following: `./demo.sh`

This will run the Python files to generate data and plot graphs, call the C programs with the PCA implementation, and clean up some of the byproducts afterwards. 

The Numpy and Matplotlib libraries are needed for the Python scripts. This script uses `bash` and the `gcc` C compiler, so those would also be needed. 
